# -*- coding: utf-8 -*-
"""Spam_Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k7yEh2oI6CvCa73Q-BsrjNRSsryt1Ffv
"""

import numpy as np
import pandas as pd

data=pd.read_csv("/content/SMSSpamCollection",sep='\t',names=["Labels","Messages"])

data.head()

data.shape

data.info()

"""Data cleaning and preprocessing"""

import re
import nltk
nltk.download("stopwords") 
nltk.download('wordnet')

from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
lm=WordNetLemmatizer() 
ps=PorterStemmer()

"""Lemmatization of Words"""

corpus=[]
for i in range(len(data)):
  review=re.sub('[^a-zA-Z]',' ',data["Messages"][i])
  review=review.lower()
  review=review.split()
  review=[lm.lemmatize(word) for word in review if word  not in set(stopwords.words('english'))]
  review=' '.join(review)
  corpus.append(review)

data.head()

"""Term Frequency and Inverse Document Frequency Model with Lammetization"""

from sklearn.feature_extraction.text import TfidfVectorizer
cv=TfidfVectorizer()
X=cv.fit_transform(corpus).toarray()

y=pd.get_dummies(data["Labels"])
y=y.iloc[:,1].values
y

"""**XGBoost Classifier**"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)
from xgboost import XGBClassifier
c=XGBClassifier()
c.fit(X_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
y_pred=c.predict(X_test)
cm=confusion_matrix(y_test,y_pred)
print(cm)
print(accuracy_score(y_test,y_pred))

from sklearn.naive_bayes import GaussianNB
gn=GaussianNB()
gn.fit(X_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
y_gb=gn.predict(X_test)
cm=confusion_matrix(y_test,y_gb)
print(cm)
print(accuracy_score(y_test,y_gb))

from sklearn.ensemble import RandomForestClassifier
rc=RandomForestClassifier(n_estimators=136,criterion='entropy',random_state=1)
rc.fit(X_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
y_rfc=rc.predict(X_test)
print(confusion_matrix(y_test,y_rfc))
print(accuracy_score(y_test,y_rfc))

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(n_neighbors=10, metric='minkowski',p=2)
knn.fit(X_train,y_train)
y_knn=rc.predict(X_test)

from sklearn.metrics import confusion_matrix,accuracy_score
y_knn=knn.predict(X_test)
print(confusion_matrix(y_test,y_knn))
print(accuracy_score(y_test,y_knn))

from sklearn.svm import SVC
svm=SVC(kernel='rbf',random_state=0)
svm.fit(X_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
y_svm=svm.predict(X_test)
print(confusion_matrix(y_test,y_svm))
print(accuracy_score(y_test,y_svm))

from sklearn.naive_bayes import MultinomialNB
nb=MultinomialNB()
nb.fit(X_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
y_nb=nb.predict(X_test)
print(confusion_matrix(y_test,y_nb))
print(accuracy_score(y_test,y_nb))

"""Best Model for Spam Classifier is Support Vector Machine with accuracy 98.11%

**Bag of Words Model with Stemming**
"""

corpu=[]
for i in range(len(data)):
  review=re.sub('[^a-zA-Z]',' ',data["Messages"][i])
  review=review.lower()
  review=review.split()
  review=[ps.stem(word) for word in review if word  not in set(stopwords.words('english'))]
  review=' '.join(review)
  corpu.append(review)

from sklearn.feature_extraction.text import CountVectorizer
c=CountVectorizer()
X=c.fit_transform(corpu).toarray()

y=pd.get_dummies(data["Labels"])
y=y.iloc[:,1].values
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)
from xgboost import XGBClassifier
c=XGBClassifier()
c.fit(X_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
y_pred=c.predict(X_test)
cm=confusion_matrix(y_test,y_pred)
print(cm)
print(accuracy_score(y_test,y_pred))

from sklearn.naive_bayes import GaussianNB
gn=GaussianNB()
gn.fit(X_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
y_gb=gn.predict(X_test)
cm=confusion_matrix(y_test,y_gb)
print(cm)
print(accuracy_score(y_test,y_gb))

from sklearn.ensemble import RandomForestClassifier
rc=RandomForestClassifier(n_estimators=136,criterion='entropy',random_state=1)
rc.fit(X_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
y_rfc=rc.predict(X_test)
print(confusion_matrix(y_test,y_rfc))
print(accuracy_score(y_test,y_rfc))

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(n_neighbors=10, metric='minkowski',p=2)
knn.fit(X_train,y_train)
y_knn=rc.predict(X_test)

from sklearn.metrics import confusion_matrix,accuracy_score
y_knn=knn.predict(X_test)
print(confusion_matrix(y_test,y_knn))
print(accuracy_score(y_test,y_knn))

from sklearn.naive_bayes import MultinomialNB
nb=MultinomialNB()
nb.fit(X_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
y_nb=nb.predict(X_test)
print(confusion_matrix(y_test,y_nb))
print(accuracy_score(y_test,y_nb))

from sklearn.svm import SVC
svm=SVC(kernel='rbf',random_state=0)
svm.fit(X_train,y_train)

from sklearn.metrics import confusion_matrix,accuracy_score
y_svm=svm.predict(X_test)
print(confusion_matrix(y_test,y_svm))
print(accuracy_score(y_test,y_svm))

"""**Best Model for Spam Classifier is Support Vector Machine with accuracy 98.11%**"""